{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          8f71ed0a819236b141978defe9a98700\n",
      "1          dc9be336b81b971c04ca98ccdf99d51e\n",
      "2          29c8ed895b8a220121168158a7447773\n",
      "3          38ee5d04ad50ddf5f6abc67017201548\n",
      "4          eef4f720e71bda0a6f1e7caa21a2c98c\n",
      "                         ...               \n",
      "1481667    a3b0502a9917c0da0c0343055d434c8f\n",
      "1481668    38aac541d4b2cef7c05b584abfcca494\n",
      "1481669    28f3dfc3160bae3b92c7c42e1082cf43\n",
      "1481670    39f8569b0ced6d11fad95d628dd05d6a\n",
      "1481671    ca917bf58677e7cd34b21d38a19ee17c\n",
      "Name: transaction_reference_id, Length: 1481672, dtype: object\n",
      "-------\n",
      "0        04ff0d1c680189e3a80c92d86407f0f5\n",
      "1        439ab0ad7380e6135ab2ff3fddd4a727\n",
      "2        00cac12d41191a84f9e31aa731a83512\n",
      "3        e4fba5f878dd3453e35973605a783a16\n",
      "4        d03d7e4c31878b0255d39e8c3f0ab625\n",
      "                       ...               \n",
      "11059    7183d9c3700148c9527869948b685085\n",
      "11060    b47b9ed0a8cc9fcc4c21ac368fe79757\n",
      "11061    d61ff2b0184f32ad0021a313c6112b2e\n",
      "11062    bec335b1b1bad8c55b7dce549cfd8de0\n",
      "11063    c2a8edf088268bddc15ec285ed730dbb\n",
      "Name: transaction_reference_id, Length: 11064, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "object_key_train = 'data/external_parties_train.csv'\n",
    "object_key_test = 'data/external_parties_test.csv'\n",
    "\n",
    "\n",
    "df_train = pd.read_csv(object_key_train)\n",
    "infos_train = df_train['party_info_unstructured']\n",
    "ids_train = df_train['transaction_reference_id']\n",
    "\n",
    "df_test = pd.read_csv(object_key_test)\n",
    "infos_test = df_test['party_info_unstructured']\n",
    "ids_test = df_test['transaction_reference_id']\n",
    "\n",
    "\n",
    "print(ids_test)\n",
    "print(\"-------\")\n",
    "print(ids_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoded test data:\n",
      "(900000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the encoded data\n",
    "with open('cluster_labels_PartialEncoder.pkl', 'rb') as f:\n",
    "    cluster_labelsPartialEncoder = pickle.load(f)\n",
    "\n",
    "print(\"Loaded encoded test data:\")\n",
    "print(cluster_labelsPartialEncoder.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1481672\n",
      "1481672\n"
     ]
    }
   ],
   "source": [
    "list_labelsPartialEncoder = cluster_labelsPartialEncoder.tolist()\n",
    "\n",
    "# append unique values to the list to make it the same length as the test data\n",
    "curr = max(list_labelsPartialEncoder) + 1\n",
    "len_list = len(list_labelsPartialEncoder)\n",
    "\n",
    "for i in range(len_list, len(infos_test)):\n",
    "    list_labelsPartialEncoder.append(curr)\n",
    "    curr += 1\n",
    "    \n",
    "print(len(list_labelsPartialEncoder))\n",
    "print(len(infos_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map each unique IBAN to a unique cluster label\n",
    "iban_to_cluster = {iban: idx for idx, iban in enumerate(df_test['party_iban'].unique())}\n",
    "iban_to_cluster[np.nan] = -1\n",
    "\n",
    "# Assign cluster labels to each row based on the IBAN\n",
    "df_test['external_id'] = df_test['party_iban'].map(iban_to_cluster)\n",
    "\n",
    "# Extract the cluster labels as an array\n",
    "cluster_labels = df_test['external_id'].values\n",
    "list_labelsIBAN = cluster_labels.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modify the cluster labels in the following way: if the cluster label is -1, we assign a unique label of the form -n with n natural number\n",
    "count = len(df_test['party_iban'].unique())\n",
    "\n",
    "for i in range(len(df_test['external_id'])):\n",
    "    if list_labelsIBAN[i] == -1:\n",
    "        list_labelsIBAN[i] = count\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.utils import UnionFind\n",
    "from collections import defaultdict\n",
    "\n",
    "def merge_clusterings(clustering1, clustering2):\n",
    "    uf = UnionFind()\n",
    "\n",
    "    dic1 = defaultdict(list)\n",
    "    dic2 = defaultdict(list)\n",
    "    for idx, label in enumerate(clustering1):\n",
    "        dic1[label].append(idx)\n",
    "    for idx, label in enumerate(clustering2):\n",
    "        dic2[label].append(idx)\n",
    "    \n",
    "    # dic1 = {label1: {idx1, idx2, ...}, label2: {idx3, idx4, ...}, ...}\n",
    "\n",
    "    for label, indices in dic1.items():\n",
    "        for idx in indices[1:]:\n",
    "            uf.union(indices[0], idx)\n",
    "    for label, indices in dic2.items():\n",
    "        for idx in indices[1:]:\n",
    "            uf.union(indices[0], idx)\n",
    "\n",
    "    return [uf[idx] for idx in range(len(clustering1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the two clusterings \n",
    "list_labelsPE_IBAN = merge_clusterings(list_labelsPartialEncoder, list_labelsIBAN)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
